{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "MV623BdUWnhh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOHfaTNrbe3v",
        "outputId": "9ffb1b13-ed82-4911-e619-b6bd11673237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n",
            "Collecting mediapipe-model-maker\n",
            "  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.4.0)\n",
            "Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)\n",
            "  Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.10.0.84)\n",
            "Collecting tensorflow<2.16,>=2.10 (from mediapipe-model-maker)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting tensorflow-addons (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.9.7)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (0.16.1)\n",
            "Collecting tensorflow-model-optimization<0.8.0 (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "Collecting tensorflow-text (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_text-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting tf-models-official<2.16.0,>=2.13.2 (from mediapipe-model-maker)\n",
            "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (24.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.8.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.68.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization<0.8.0->mediapipe-model-maker) (0.1.8)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.0.11)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (11.0.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.155.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.6.17)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.10.0.84)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.0.8)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.0.2)\n",
            "Collecting sacrebleu (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.13.1)\n",
            "Collecting seqeval (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-text (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.1.0)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub->mediapipe-model-maker) (2.17.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (8.1.7)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (17.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.32.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.67.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (1.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.45.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (3.21.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.10)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.17.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.1.3)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub->mediapipe-model-maker)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (3.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.6.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->mediapipe-model-maker) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.66.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.22)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.25.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.5.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.3.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.2.2)\n",
            "Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl (133 kB)\n",
            "Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "Downloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=8d77fd77176586b20e5c47dedc98d2bc6e5a70539fb06f70e447d55116a728e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: wrapt, typeguard, tensorflow-model-optimization, tensorflow-estimator, portalocker, ml-dtypes, keras, colorama, tensorflow-addons, sounddevice, sacrebleu, seqeval, tensorboard, mediapipe, tensorflow, tf-keras, tensorflow-text, tf-models-official, mediapipe-model-maker\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 keras-2.15.0 mediapipe-0.10.20 mediapipe-model-maker-0.2.1.4 ml-dtypes-0.3.2 portalocker-3.0.0 sacrebleu-2.4.3 seqeval-1.2.2 sounddevice-0.5.1 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-keras-2.15.1 tf-models-official-2.15.0 typeguard-2.13.3 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj2Z0U25byZT",
        "outputId": "8e85a7fd-6e3d-4329-b83e-36756bda8020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from mediapipe_model_maker import image_classifier\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Dataset"
      ],
      "metadata": {
        "id": "xtYUcoU0Wwaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "56cIsfwK5YQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10117d12-a4db-454a-a5ca-e262c32f9a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#save final weights to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRUe01fg1wmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee82489e-c0ea-4e83-e2a8-4864f5898284"
      },
      "source": [
        "zip_file_name = \"/content/drive/MyDrive/Dataset/dataset\" #@param {type:\"string\"}\n",
        "!unzip {zip_file_name}.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Dataset/dataset.zip\n",
            "   creating: dataset/\n",
            "   creating: dataset/apple/\n",
            "  inflating: dataset/apple/Image_1.jpg  \n",
            "  inflating: dataset/apple/Image_10.jpg  \n",
            "  inflating: dataset/apple/Image_16.jpg  \n",
            "  inflating: dataset/apple/Image_17.jpg  \n",
            "  inflating: dataset/apple/Image_18.jpg  \n",
            "  inflating: dataset/apple/Image_19.jpg  \n",
            "  inflating: dataset/apple/Image_2.jpg  \n",
            "  inflating: dataset/apple/Image_20.jpg  \n",
            "  inflating: dataset/apple/Image_21.jpg  \n",
            "  inflating: dataset/apple/Image_23.jpg  \n",
            "  inflating: dataset/apple/Image_24.jpg  \n",
            "  inflating: dataset/apple/Image_25.jpg  \n",
            "  inflating: dataset/apple/Image_26.jpg  \n",
            "  inflating: dataset/apple/Image_27.jpg  \n",
            "  inflating: dataset/apple/Image_28.jpg  \n",
            "  inflating: dataset/apple/Image_3.jpg  \n",
            "  inflating: dataset/apple/Image_31.jpg  \n",
            "  inflating: dataset/apple/Image_32.jpg  \n",
            "  inflating: dataset/apple/Image_33.jpg  \n",
            "  inflating: dataset/apple/Image_34.jpg  \n",
            "  inflating: dataset/apple/Image_35.png  \n",
            "  inflating: dataset/apple/Image_36.jpg  \n",
            "  inflating: dataset/apple/Image_37.jpg  \n",
            "  inflating: dataset/apple/Image_38.jpg  \n",
            "  inflating: dataset/apple/Image_39.jpg  \n",
            "  inflating: dataset/apple/Image_40.jpg  \n",
            "  inflating: dataset/apple/Image_41.jpg  \n",
            "  inflating: dataset/apple/Image_42.jpg  \n",
            "  inflating: dataset/apple/Image_43.jpg  \n",
            "  inflating: dataset/apple/Image_44.jpg  \n",
            "  inflating: dataset/apple/Image_45.jpg  \n",
            "  inflating: dataset/apple/Image_47.jpg  \n",
            "  inflating: dataset/apple/Image_48.jpg  \n",
            "  inflating: dataset/apple/Image_49.jpg  \n",
            "  inflating: dataset/apple/Image_5.JPG  \n",
            "  inflating: dataset/apple/Image_50.jpg  \n",
            "  inflating: dataset/apple/Image_51.jpg  \n",
            "  inflating: dataset/apple/Image_52.jpg  \n",
            "  inflating: dataset/apple/Image_53.png  \n",
            "  inflating: dataset/apple/Image_54.jpg  \n",
            "  inflating: dataset/apple/Image_55.jpg  \n",
            "  inflating: dataset/apple/Image_56.jpg  \n",
            "  inflating: dataset/apple/Image_57.jpg  \n",
            "  inflating: dataset/apple/Image_58.jpg  \n",
            "  inflating: dataset/apple/Image_59.png  \n",
            "  inflating: dataset/apple/Image_6.jpg  \n",
            "  inflating: dataset/apple/Image_60.jpg  \n",
            "  inflating: dataset/apple/Image_61.jpg  \n",
            "  inflating: dataset/apple/Image_62.jpg  \n",
            "  inflating: dataset/apple/Image_63.jpg  \n",
            "  inflating: dataset/apple/Image_64.jpg  \n",
            "  inflating: dataset/apple/Image_65.png  \n",
            "  inflating: dataset/apple/Image_67.jpg  \n",
            "  inflating: dataset/apple/Image_68.jpg  \n",
            "  inflating: dataset/apple/Image_69.jpg  \n",
            "  inflating: dataset/apple/Image_7.jpg  \n",
            "  inflating: dataset/apple/Image_71.png  \n",
            "  inflating: dataset/apple/Image_76.png  \n",
            "  inflating: dataset/apple/Image_78.jpg  \n",
            "  inflating: dataset/apple/Image_80.jpg  \n",
            "  inflating: dataset/apple/Image_81.png  \n",
            "  inflating: dataset/apple/Image_82.jpg  \n",
            "  inflating: dataset/apple/Image_83.png  \n",
            "  inflating: dataset/apple/Image_86.jpg  \n",
            "  inflating: dataset/apple/Image_87.jpg  \n",
            "  inflating: dataset/apple/Image_9.jpg  \n",
            "  inflating: dataset/apple/Image_90.jpg  \n",
            "  inflating: dataset/apple/Image_92.png  \n",
            "   creating: dataset/banana/\n",
            "  inflating: dataset/banana/Image_1.jpg  \n",
            "  inflating: dataset/banana/Image_100.jpg  \n",
            "  inflating: dataset/banana/Image_11.png  \n",
            "  inflating: dataset/banana/Image_13.jpg  \n",
            "  inflating: dataset/banana/Image_14.jpg  \n",
            "  inflating: dataset/banana/Image_15.jpg  \n",
            "  inflating: dataset/banana/Image_16.jpg  \n",
            "  inflating: dataset/banana/Image_21.JPG  \n",
            "  inflating: dataset/banana/Image_23.jpg  \n",
            "  inflating: dataset/banana/Image_24.jpg  \n",
            "  inflating: dataset/banana/Image_25.jpg  \n",
            "  inflating: dataset/banana/Image_27.jpg  \n",
            "  inflating: dataset/banana/Image_28.jpg  \n",
            "  inflating: dataset/banana/Image_3.jpg  \n",
            "  inflating: dataset/banana/Image_31.jpg  \n",
            "  inflating: dataset/banana/Image_32.jpg  \n",
            "  inflating: dataset/banana/Image_37.jpg  \n",
            "  inflating: dataset/banana/Image_4.jpg  \n",
            "  inflating: dataset/banana/Image_40.jpg  \n",
            "  inflating: dataset/banana/Image_41.jpg  \n",
            "  inflating: dataset/banana/Image_42.jpg  \n",
            "  inflating: dataset/banana/Image_43.png  \n",
            "  inflating: dataset/banana/Image_44.jpg  \n",
            "  inflating: dataset/banana/Image_45.jpg  \n",
            "  inflating: dataset/banana/Image_46.jpg  \n",
            "  inflating: dataset/banana/Image_47.jpg  \n",
            "  inflating: dataset/banana/Image_48.png  \n",
            "  inflating: dataset/banana/Image_49.jpg  \n",
            "  inflating: dataset/banana/Image_5.jpg  \n",
            "  inflating: dataset/banana/Image_50.jpg  \n",
            "  inflating: dataset/banana/Image_51.jpeg  \n",
            "  inflating: dataset/banana/Image_52.jpg  \n",
            "  inflating: dataset/banana/Image_53.png  \n",
            "  inflating: dataset/banana/Image_54.jpg  \n",
            "  inflating: dataset/banana/Image_55.jpg  \n",
            "  inflating: dataset/banana/Image_56.jpg  \n",
            "  inflating: dataset/banana/Image_57.jpg  \n",
            "  inflating: dataset/banana/Image_58.png  \n",
            "  inflating: dataset/banana/Image_59.jpg  \n",
            "  inflating: dataset/banana/Image_6.jpg  \n",
            "  inflating: dataset/banana/Image_61.png  \n",
            "  inflating: dataset/banana/Image_62.jpg  \n",
            "  inflating: dataset/banana/Image_63.jpg  \n",
            "  inflating: dataset/banana/Image_64.jpg  \n",
            "  inflating: dataset/banana/Image_65.png  \n",
            "  inflating: dataset/banana/Image_66.jpg  \n",
            "  inflating: dataset/banana/Image_67.jpg  \n",
            "  inflating: dataset/banana/Image_68.jpg  \n",
            "  inflating: dataset/banana/Image_69.jpg  \n",
            "  inflating: dataset/banana/Image_71.jpg  \n",
            "  inflating: dataset/banana/Image_72.jpg  \n",
            "  inflating: dataset/banana/Image_73.jpg  \n",
            "  inflating: dataset/banana/Image_75.jpg  \n",
            "  inflating: dataset/banana/Image_76.jpg  \n",
            "  inflating: dataset/banana/Image_77.jpg  \n",
            "  inflating: dataset/banana/Image_79.jpg  \n",
            "  inflating: dataset/banana/Image_8.jpg  \n",
            "  inflating: dataset/banana/Image_80.png  \n",
            "  inflating: dataset/banana/Image_81.jpeg  \n",
            "  inflating: dataset/banana/Image_82.jpg  \n",
            "  inflating: dataset/banana/Image_83.png  \n",
            "  inflating: dataset/banana/Image_84.jpg  \n",
            "  inflating: dataset/banana/Image_85.jpg  \n",
            "  inflating: dataset/banana/Image_86.jpg  \n",
            "  inflating: dataset/banana/Image_88.png  \n",
            "  inflating: dataset/banana/Image_89.jpg  \n",
            "  inflating: dataset/banana/Image_9.jpg  \n",
            "  inflating: dataset/banana/Image_90.jpg  \n",
            "  inflating: dataset/banana/Image_91.jpg  \n",
            "  inflating: dataset/banana/Image_92.jpg  \n",
            "  inflating: dataset/banana/Image_93.jpg  \n",
            "  inflating: dataset/banana/Image_95.jpg  \n",
            "  inflating: dataset/banana/Image_96.jpg  \n",
            "  inflating: dataset/banana/Image_97.jpg  \n",
            "  inflating: dataset/banana/Image_98.jpg  \n",
            "   creating: dataset/lemon/\n",
            "  inflating: dataset/lemon/Image_1.png  \n",
            "  inflating: dataset/lemon/Image_10.jpg  \n",
            "  inflating: dataset/lemon/Image_100.png  \n",
            "  inflating: dataset/lemon/Image_11.jpg  \n",
            "  inflating: dataset/lemon/Image_12.jpg  \n",
            "  inflating: dataset/lemon/Image_13.jpg  \n",
            "  inflating: dataset/lemon/Image_14.jpg  \n",
            "  inflating: dataset/lemon/Image_15.JPG  \n",
            "  inflating: dataset/lemon/Image_16.jpg  \n",
            "  inflating: dataset/lemon/Image_17.jpg  \n",
            "  inflating: dataset/lemon/Image_18.jpg  \n",
            "  inflating: dataset/lemon/Image_19.jpg  \n",
            "  inflating: dataset/lemon/Image_2.jpg  \n",
            "  inflating: dataset/lemon/Image_21.jpg  \n",
            "  inflating: dataset/lemon/Image_22.jpg  \n",
            "  inflating: dataset/lemon/Image_23.jpg  \n",
            "  inflating: dataset/lemon/Image_24.jpg  \n",
            "  inflating: dataset/lemon/Image_25.jpg  \n",
            "  inflating: dataset/lemon/Image_27.jpg  \n",
            "  inflating: dataset/lemon/Image_28.jpg  \n",
            "  inflating: dataset/lemon/Image_29.jpeg  \n",
            "  inflating: dataset/lemon/Image_3.jpg  \n",
            "  inflating: dataset/lemon/Image_30.jpg  \n",
            "  inflating: dataset/lemon/Image_31.jpg  \n",
            "  inflating: dataset/lemon/Image_32.jpg  \n",
            "  inflating: dataset/lemon/Image_33.jpeg  \n",
            "  inflating: dataset/lemon/Image_34.jpg  \n",
            "  inflating: dataset/lemon/Image_35.jpg  \n",
            "  inflating: dataset/lemon/Image_36.png  \n",
            "  inflating: dataset/lemon/Image_37.png  \n",
            "  inflating: dataset/lemon/Image_38.jpg  \n",
            "  inflating: dataset/lemon/Image_39.png  \n",
            "  inflating: dataset/lemon/Image_4.jpg  \n",
            "  inflating: dataset/lemon/Image_41.jpg  \n",
            "  inflating: dataset/lemon/Image_42.jpg  \n",
            "  inflating: dataset/lemon/Image_43.jpeg  \n",
            "  inflating: dataset/lemon/Image_44.jpg  \n",
            "  inflating: dataset/lemon/Image_45.png  \n",
            "  inflating: dataset/lemon/Image_47.jpg  \n",
            "  inflating: dataset/lemon/Image_48.jpg  \n",
            "  inflating: dataset/lemon/Image_49.jpg  \n",
            "  inflating: dataset/lemon/Image_5.jpg  \n",
            "  inflating: dataset/lemon/Image_50.jpg  \n",
            "  inflating: dataset/lemon/Image_51.jpg  \n",
            "  inflating: dataset/lemon/Image_52.png  \n",
            "  inflating: dataset/lemon/Image_53.jpg  \n",
            "  inflating: dataset/lemon/Image_54.jpg  \n",
            "  inflating: dataset/lemon/Image_55.jpg  \n",
            "  inflating: dataset/lemon/Image_56.jpg  \n",
            "  inflating: dataset/lemon/Image_57.jpg  \n",
            "  inflating: dataset/lemon/Image_58.jpg  \n",
            "  inflating: dataset/lemon/Image_6.png  \n",
            "  inflating: dataset/lemon/Image_60.jpg  \n",
            "  inflating: dataset/lemon/Image_61.png  \n",
            "  inflating: dataset/lemon/Image_63.jpg  \n",
            "  inflating: dataset/lemon/Image_64.png  \n",
            "  inflating: dataset/lemon/Image_65.jpg  \n",
            "  inflating: dataset/lemon/Image_69.jpg  \n",
            "  inflating: dataset/lemon/Image_7.jpg  \n",
            "  inflating: dataset/lemon/Image_70.jpg  \n",
            "  inflating: dataset/lemon/Image_71.jpg  \n",
            "  inflating: dataset/lemon/Image_74.jpg  \n",
            "  inflating: dataset/lemon/Image_75.jpg  \n",
            "  inflating: dataset/lemon/Image_76.jpeg  \n",
            "  inflating: dataset/lemon/Image_77.jpg  \n",
            "  inflating: dataset/lemon/Image_78.jpg  \n",
            "  inflating: dataset/lemon/Image_8.png  \n",
            "  inflating: dataset/lemon/Image_80.jpg  \n",
            "  inflating: dataset/lemon/Image_84.jpg  \n",
            "  inflating: dataset/lemon/Image_85.jpg  \n",
            "  inflating: dataset/lemon/Image_87.png  \n",
            "  inflating: dataset/lemon/Image_88.jpg  \n",
            "  inflating: dataset/lemon/Image_9.jpg  \n",
            "  inflating: dataset/lemon/Image_90.jpg  \n",
            "  inflating: dataset/lemon/Image_92.jpg  \n",
            "  inflating: dataset/lemon/Image_93.jpg  \n",
            "  inflating: dataset/lemon/Image_94.jpg  \n",
            "  inflating: dataset/lemon/Image_95.png  \n",
            "  inflating: dataset/lemon/Image_96.jpg  \n",
            "  inflating: dataset/lemon/Image_97.jpg  \n",
            "  inflating: dataset/lemon/Image_98.jpg  \n",
            "  inflating: dataset/lemon/Image_99.jpg  \n",
            "   creating: dataset/onion/\n",
            "  inflating: dataset/onion/Image_1.jpg  \n",
            "  inflating: dataset/onion/Image_10.jpg  \n",
            "  inflating: dataset/onion/Image_100.jpg  \n",
            "  inflating: dataset/onion/Image_11.jpg  \n",
            "  inflating: dataset/onion/Image_12.jpg  \n",
            "  inflating: dataset/onion/Image_13.jpg  \n",
            "  inflating: dataset/onion/Image_14.jpg  \n",
            "  inflating: dataset/onion/Image_15.jpg  \n",
            "  inflating: dataset/onion/Image_16.jpg  \n",
            "  inflating: dataset/onion/Image_17.jpg  \n",
            "  inflating: dataset/onion/Image_18.jpg  \n",
            "  inflating: dataset/onion/Image_19.jpg  \n",
            "  inflating: dataset/onion/Image_2.jpg  \n",
            "  inflating: dataset/onion/Image_20.jpg  \n",
            "  inflating: dataset/onion/Image_21.jpg  \n",
            "  inflating: dataset/onion/Image_22.jpg  \n",
            "  inflating: dataset/onion/Image_23.jpg  \n",
            "  inflating: dataset/onion/Image_24.jpg  \n",
            "  inflating: dataset/onion/Image_25.jpg  \n",
            "  inflating: dataset/onion/Image_26.jpg  \n",
            "  inflating: dataset/onion/Image_27.jpg  \n",
            "  inflating: dataset/onion/Image_28.jpg  \n",
            "  inflating: dataset/onion/Image_29.jpg  \n",
            "  inflating: dataset/onion/Image_3.jpg  \n",
            "  inflating: dataset/onion/Image_30.jpg  \n",
            "  inflating: dataset/onion/Image_31.png  \n",
            "  inflating: dataset/onion/Image_32.jpg  \n",
            "  inflating: dataset/onion/Image_33.png  \n",
            "  inflating: dataset/onion/Image_34.png  \n",
            "  inflating: dataset/onion/Image_35.png  \n",
            "  inflating: dataset/onion/Image_36.jpg  \n",
            "  inflating: dataset/onion/Image_37.png  \n",
            "  inflating: dataset/onion/Image_38.jpg  \n",
            "  inflating: dataset/onion/Image_39.jpg  \n",
            "  inflating: dataset/onion/Image_4.jpg  \n",
            "  inflating: dataset/onion/Image_40.jpg  \n",
            "  inflating: dataset/onion/Image_41.jpg  \n",
            "  inflating: dataset/onion/Image_42.JPG  \n",
            "  inflating: dataset/onion/Image_43.jpg  \n",
            "  inflating: dataset/onion/Image_45.jpg  \n",
            "  inflating: dataset/onion/Image_46.jpg  \n",
            "  inflating: dataset/onion/Image_47.jpg  \n",
            "  inflating: dataset/onion/Image_48.jpg  \n",
            "  inflating: dataset/onion/Image_49.png  \n",
            "  inflating: dataset/onion/Image_5.jpg  \n",
            "  inflating: dataset/onion/Image_50.jpg  \n",
            "  inflating: dataset/onion/Image_52.jpg  \n",
            "  inflating: dataset/onion/Image_53.jpg  \n",
            "  inflating: dataset/onion/Image_54.jpg  \n",
            "  inflating: dataset/onion/Image_55.jpg  \n",
            "  inflating: dataset/onion/Image_56.jpg  \n",
            "  inflating: dataset/onion/Image_58.jpg  \n",
            "  inflating: dataset/onion/Image_59.jpg  \n",
            "  inflating: dataset/onion/Image_6.jpg  \n",
            "  inflating: dataset/onion/Image_60.jpg  \n",
            "  inflating: dataset/onion/Image_61.jpg  \n",
            "  inflating: dataset/onion/Image_62.jpg  \n",
            "  inflating: dataset/onion/Image_63.png  \n",
            "  inflating: dataset/onion/Image_64.jpeg  \n",
            "  inflating: dataset/onion/Image_65.jpg  \n",
            "  inflating: dataset/onion/Image_66.jpg  \n",
            "  inflating: dataset/onion/Image_68.png  \n",
            "  inflating: dataset/onion/Image_69.jpg  \n",
            "  inflating: dataset/onion/Image_7.jpg  \n",
            "  inflating: dataset/onion/Image_70.jpg  \n",
            "  inflating: dataset/onion/Image_71.png  \n",
            "  inflating: dataset/onion/Image_72.jpg  \n",
            "  inflating: dataset/onion/Image_73.jpg  \n",
            "  inflating: dataset/onion/Image_74.jpg  \n",
            "  inflating: dataset/onion/Image_75.jpg  \n",
            "  inflating: dataset/onion/Image_78.png  \n",
            "  inflating: dataset/onion/Image_79.jpg  \n",
            "  inflating: dataset/onion/Image_8.jpg  \n",
            "  inflating: dataset/onion/Image_80.jpg  \n",
            "  inflating: dataset/onion/Image_81.jpg  \n",
            "  inflating: dataset/onion/Image_82.jpg  \n",
            "  inflating: dataset/onion/Image_83.jpg  \n",
            "  inflating: dataset/onion/Image_84.jpg  \n",
            "  inflating: dataset/onion/Image_85.jpg  \n",
            "  inflating: dataset/onion/Image_86.jpg  \n",
            "  inflating: dataset/onion/Image_87.jpg  \n",
            "  inflating: dataset/onion/Image_88.jpg  \n",
            "  inflating: dataset/onion/Image_89.jpg  \n",
            "  inflating: dataset/onion/Image_9.png  \n",
            "  inflating: dataset/onion/Image_90.jpg  \n",
            "  inflating: dataset/onion/Image_91.jpg  \n",
            "  inflating: dataset/onion/Image_92.jpg  \n",
            "  inflating: dataset/onion/Image_93.jpg  \n",
            "  inflating: dataset/onion/Image_94.png  \n",
            "  inflating: dataset/onion/Image_95.jpg  \n",
            "  inflating: dataset/onion/Image_96.jpg  \n",
            "  inflating: dataset/onion/Image_97.jpg  \n",
            "  inflating: dataset/onion/Image_98.jpg  \n",
            "  inflating: dataset/onion/Image_99.jpg  \n",
            "   creating: dataset/watermelon/\n",
            "  inflating: dataset/watermelon/Image_1.jpg  \n",
            "  inflating: dataset/watermelon/Image_10.jpg  \n",
            "  inflating: dataset/watermelon/Image_100.jpg  \n",
            "  inflating: dataset/watermelon/Image_13.jpg  \n",
            "  inflating: dataset/watermelon/Image_14.jpeg  \n",
            "  inflating: dataset/watermelon/Image_15.jpg  \n",
            "  inflating: dataset/watermelon/Image_16.jpg  \n",
            "  inflating: dataset/watermelon/Image_17.jpg  \n",
            "  inflating: dataset/watermelon/Image_18.jpg  \n",
            "  inflating: dataset/watermelon/Image_19.png  \n",
            "  inflating: dataset/watermelon/Image_2.jpg  \n",
            "  inflating: dataset/watermelon/Image_20.jpg  \n",
            "  inflating: dataset/watermelon/Image_21.jpg  \n",
            "  inflating: dataset/watermelon/Image_22.jpg  \n",
            "  inflating: dataset/watermelon/Image_23.jpg  \n",
            "  inflating: dataset/watermelon/Image_24.jpg  \n",
            "  inflating: dataset/watermelon/Image_25.jpg  \n",
            "  inflating: dataset/watermelon/Image_26.jpg  \n",
            "  inflating: dataset/watermelon/Image_27.jpg  \n",
            "  inflating: dataset/watermelon/Image_28.jpg  \n",
            "  inflating: dataset/watermelon/Image_29.jpg  \n",
            "  inflating: dataset/watermelon/Image_3.jpg  \n",
            "  inflating: dataset/watermelon/Image_30.jpg  \n",
            "  inflating: dataset/watermelon/Image_31.JPG  \n",
            "  inflating: dataset/watermelon/Image_32.jpg  \n",
            "  inflating: dataset/watermelon/Image_33.png  \n",
            "  inflating: dataset/watermelon/Image_34.jpg  \n",
            "  inflating: dataset/watermelon/Image_35.jpg  \n",
            "  inflating: dataset/watermelon/Image_36.jpg  \n",
            "  inflating: dataset/watermelon/Image_37.jpg  \n",
            "  inflating: dataset/watermelon/Image_38.jpg  \n",
            "  inflating: dataset/watermelon/Image_39.jpg  \n",
            "  inflating: dataset/watermelon/Image_4.jpg  \n",
            "  inflating: dataset/watermelon/Image_40.jpg  \n",
            "  inflating: dataset/watermelon/Image_41.jpg  \n",
            "  inflating: dataset/watermelon/Image_42.jpg  \n",
            "  inflating: dataset/watermelon/Image_43.jpg  \n",
            "  inflating: dataset/watermelon/Image_44.jpg  \n",
            "  inflating: dataset/watermelon/Image_45.jpg  \n",
            "  inflating: dataset/watermelon/Image_46.jpg  \n",
            "  inflating: dataset/watermelon/Image_47.jpg  \n",
            "  inflating: dataset/watermelon/Image_49.jpg  \n",
            "  inflating: dataset/watermelon/Image_5.jpg  \n",
            "  inflating: dataset/watermelon/Image_50.jpg  \n",
            "  inflating: dataset/watermelon/Image_51.jpg  \n",
            "  inflating: dataset/watermelon/Image_52.jpg  \n",
            "  inflating: dataset/watermelon/Image_53.jpg  \n",
            "  inflating: dataset/watermelon/Image_55.jpg  \n",
            "  inflating: dataset/watermelon/Image_56.jpg  \n",
            "  inflating: dataset/watermelon/Image_57.jpg  \n",
            "  inflating: dataset/watermelon/Image_58.jpg  \n",
            "  inflating: dataset/watermelon/Image_59.jpg  \n",
            "  inflating: dataset/watermelon/Image_6.jpg  \n",
            "  inflating: dataset/watermelon/Image_61.jpg  \n",
            "  inflating: dataset/watermelon/Image_62.jpg  \n",
            "  inflating: dataset/watermelon/Image_63.jpg  \n",
            "  inflating: dataset/watermelon/Image_65.jpg  \n",
            "  inflating: dataset/watermelon/Image_66.jpg  \n",
            "  inflating: dataset/watermelon/Image_67.jpg  \n",
            "  inflating: dataset/watermelon/Image_68.jpg  \n",
            "  inflating: dataset/watermelon/Image_69.jpg  \n",
            "  inflating: dataset/watermelon/Image_7.jpg  \n",
            "  inflating: dataset/watermelon/Image_70.jpg  \n",
            "  inflating: dataset/watermelon/Image_73.jpg  \n",
            "  inflating: dataset/watermelon/Image_78.jpg  \n",
            "  inflating: dataset/watermelon/Image_79.jpg  \n",
            "  inflating: dataset/watermelon/Image_8.jpg  \n",
            "  inflating: dataset/watermelon/Image_81.jpg  \n",
            "  inflating: dataset/watermelon/Image_83.jpg  \n",
            "  inflating: dataset/watermelon/Image_84.jpg  \n",
            "  inflating: dataset/watermelon/Image_85.jpg  \n",
            "  inflating: dataset/watermelon/Image_86.jpg  \n",
            "  inflating: dataset/watermelon/Image_88.jpg  \n",
            "  inflating: dataset/watermelon/Image_89.png  \n",
            "  inflating: dataset/watermelon/Image_9.jpg  \n",
            "  inflating: dataset/watermelon/Image_90.jpg  \n",
            "  inflating: dataset/watermelon/Image_91.jpg  \n",
            "  inflating: dataset/watermelon/Image_92.jpg  \n",
            "  inflating: dataset/watermelon/Image_94.jpg  \n",
            "  inflating: dataset/watermelon/Image_95.jpg  \n",
            "  inflating: dataset/watermelon/Image_96.jpg  \n",
            "  inflating: dataset/watermelon/Image_97.jpg  \n",
            "  inflating: dataset/watermelon/Image_98.jpg  \n",
            "  inflating: dataset/watermelon/Image_99.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h1bxmGDqjvq"
      },
      "source": [
        "image_path = '/content/dataset'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6h7tu1tdcGp",
        "outputId": "52a80e74-be1f-4d50-eca5-988ce4d9b2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset\n",
            "['lemon', 'banana', 'onion', 'apple', 'watermelon']\n"
          ]
        }
      ],
      "source": [
        "print(image_path)\n",
        "labels = []\n",
        "for i in os.listdir(image_path):\n",
        "  if os.path.isdir(os.path.join(image_path, i)):\n",
        "    labels.append(i)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "G-csvUN1dheJ"
      },
      "outputs": [],
      "source": [
        "NUM_EXAMPLES = 5\n",
        "\n",
        "for label in labels:\n",
        "  label_dir = os.path.join(image_path, label)\n",
        "  example_filenames = os.listdir(label_dir)[:NUM_EXAMPLES]\n",
        "  fig, axs = plt.subplots(1, NUM_EXAMPLES, figsize=(10,2))\n",
        "  for i in range(NUM_EXAMPLES):\n",
        "    axs[i].imshow(plt.imread(os.path.join(label_dir, example_filenames[i])))\n",
        "    axs[i].get_xaxis().set_visible(False)\n",
        "    axs[i].get_yaxis().set_visible(False)\n",
        "  fig.suptitle(f'Showing {NUM_EXAMPLES} examples for {label}')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MKJP_8wudnI5"
      },
      "outputs": [],
      "source": [
        "data = image_classifier.Dataset.from_folder(image_path)\n",
        "train_data, remaining_data = data.split(0.9)\n",
        "test_data, validation_data = remaining_data.split(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "FJctF7BzW4JJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "P2-1IxmXdrYh"
      },
      "outputs": [],
      "source": [
        "spec = image_classifier.SupportedModels.EFFICIENTNET_LITE2\n",
        "hparams = image_classifier.HParams(export_dir=\"exported_model\",epochs=50)\n",
        "options = image_classifier.ImageClassifierOptions(supported_model=spec, hparams=hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgPL3hMAdvah",
        "outputId": "94bada48-2989-486a-adab-f6f37a02aed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              4869168   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 6405      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4875573 (18.60 MB)\n",
            "Trainable params: 6405 (25.02 KB)\n",
            "Non-trainable params: 4869168 (18.57 MB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: resize_bicubic (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.image.resize(...method=ResizeMethod.BICUBIC...)` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "181/181 [==============================] - 67s 351ms/step - loss: 1.6083 - accuracy: 0.2265 - val_loss: 1.4295 - val_accuracy: 0.4286\n",
            "Epoch 2/50\n",
            "181/181 [==============================] - 55s 303ms/step - loss: 1.4690 - accuracy: 0.3702 - val_loss: 1.3146 - val_accuracy: 0.6190\n",
            "Epoch 3/50\n",
            "181/181 [==============================] - 60s 331ms/step - loss: 1.2786 - accuracy: 0.6077 - val_loss: 1.1591 - val_accuracy: 0.7143\n",
            "Epoch 4/50\n",
            "181/181 [==============================] - 53s 293ms/step - loss: 1.1146 - accuracy: 0.7541 - val_loss: 1.0295 - val_accuracy: 0.7619\n",
            "Epoch 5/50\n",
            "181/181 [==============================] - 63s 346ms/step - loss: 0.9446 - accuracy: 0.8343 - val_loss: 0.9099 - val_accuracy: 0.8095\n",
            "Epoch 6/50\n",
            "181/181 [==============================] - 53s 291ms/step - loss: 0.8591 - accuracy: 0.8840 - val_loss: 0.8186 - val_accuracy: 0.9048\n",
            "Epoch 7/50\n",
            "181/181 [==============================] - 62s 344ms/step - loss: 0.7453 - accuracy: 0.9227 - val_loss: 0.7471 - val_accuracy: 0.9048\n",
            "Epoch 8/50\n",
            "181/181 [==============================] - 62s 344ms/step - loss: 0.7218 - accuracy: 0.9199 - val_loss: 0.6871 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "181/181 [==============================] - 60s 332ms/step - loss: 0.6616 - accuracy: 0.9475 - val_loss: 0.6422 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "181/181 [==============================] - 60s 331ms/step - loss: 0.6401 - accuracy: 0.9475 - val_loss: 0.6118 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "181/181 [==============================] - 62s 341ms/step - loss: 0.6012 - accuracy: 0.9503 - val_loss: 0.5830 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "181/181 [==============================] - 61s 338ms/step - loss: 0.5813 - accuracy: 0.9558 - val_loss: 0.5627 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "181/181 [==============================] - 60s 332ms/step - loss: 0.5647 - accuracy: 0.9586 - val_loss: 0.5436 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "181/181 [==============================] - 62s 341ms/step - loss: 0.5676 - accuracy: 0.9475 - val_loss: 0.5292 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "181/181 [==============================] - 63s 348ms/step - loss: 0.5337 - accuracy: 0.9613 - val_loss: 0.5182 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "181/181 [==============================] - 52s 290ms/step - loss: 0.5413 - accuracy: 0.9558 - val_loss: 0.5138 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "181/181 [==============================] - 55s 302ms/step - loss: 0.5468 - accuracy: 0.9558 - val_loss: 0.5033 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "181/181 [==============================] - 60s 331ms/step - loss: 0.5491 - accuracy: 0.9365 - val_loss: 0.4964 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "181/181 [==============================] - 61s 336ms/step - loss: 0.5450 - accuracy: 0.9613 - val_loss: 0.4902 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "181/181 [==============================] - 62s 341ms/step - loss: 0.5344 - accuracy: 0.9613 - val_loss: 0.4874 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "181/181 [==============================] - 53s 294ms/step - loss: 0.5165 - accuracy: 0.9613 - val_loss: 0.4836 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "181/181 [==============================] - 60s 333ms/step - loss: 0.5086 - accuracy: 0.9669 - val_loss: 0.4798 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "181/181 [==============================] - 63s 347ms/step - loss: 0.5054 - accuracy: 0.9724 - val_loss: 0.4764 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "181/181 [==============================] - 62s 344ms/step - loss: 0.5278 - accuracy: 0.9586 - val_loss: 0.4758 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "181/181 [==============================] - 60s 331ms/step - loss: 0.5187 - accuracy: 0.9669 - val_loss: 0.4731 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "181/181 [==============================] - 60s 332ms/step - loss: 0.5372 - accuracy: 0.9475 - val_loss: 0.4719 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "181/181 [==============================] - 62s 344ms/step - loss: 0.5111 - accuracy: 0.9724 - val_loss: 0.4707 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "181/181 [==============================] - 53s 291ms/step - loss: 0.4978 - accuracy: 0.9724 - val_loss: 0.4700 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "181/181 [==============================] - 61s 339ms/step - loss: 0.5069 - accuracy: 0.9669 - val_loss: 0.4668 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "181/181 [==============================] - 62s 342ms/step - loss: 0.5086 - accuracy: 0.9613 - val_loss: 0.4625 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "181/181 [==============================] - 60s 333ms/step - loss: 0.4939 - accuracy: 0.9724 - val_loss: 0.4610 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "181/181 [==============================] - 62s 340ms/step - loss: 0.5006 - accuracy: 0.9779 - val_loss: 0.4604 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "181/181 [==============================] - 53s 294ms/step - loss: 0.5115 - accuracy: 0.9641 - val_loss: 0.4593 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "181/181 [==============================] - 56s 307ms/step - loss: 0.5019 - accuracy: 0.9696 - val_loss: 0.4585 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "181/181 [==============================] - 60s 332ms/step - loss: 0.4978 - accuracy: 0.9751 - val_loss: 0.4564 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "181/181 [==============================] - 53s 294ms/step - loss: 0.5001 - accuracy: 0.9751 - val_loss: 0.4572 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "181/181 [==============================] - 67s 370ms/step - loss: 0.5009 - accuracy: 0.9724 - val_loss: 0.4562 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "181/181 [==============================] - 55s 306ms/step - loss: 0.4810 - accuracy: 0.9890 - val_loss: 0.4564 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "181/181 [==============================] - 60s 331ms/step - loss: 0.5093 - accuracy: 0.9669 - val_loss: 0.4555 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "181/181 [==============================] - 62s 341ms/step - loss: 0.4868 - accuracy: 0.9724 - val_loss: 0.4541 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "181/181 [==============================] - 53s 294ms/step - loss: 0.5012 - accuracy: 0.9613 - val_loss: 0.4542 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "181/181 [==============================] - 62s 343ms/step - loss: 0.4859 - accuracy: 0.9779 - val_loss: 0.4536 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "181/181 [==============================] - 60s 332ms/step - loss: 0.4943 - accuracy: 0.9724 - val_loss: 0.4525 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "181/181 [==============================] - 53s 293ms/step - loss: 0.5087 - accuracy: 0.9751 - val_loss: 0.4528 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "181/181 [==============================] - 56s 311ms/step - loss: 0.5079 - accuracy: 0.9586 - val_loss: 0.4528 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "181/181 [==============================] - 60s 333ms/step - loss: 0.4902 - accuracy: 0.9779 - val_loss: 0.4499 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "181/181 [==============================] - 53s 295ms/step - loss: 0.4844 - accuracy: 0.9807 - val_loss: 0.4488 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "181/181 [==============================] - 62s 345ms/step - loss: 0.4992 - accuracy: 0.9586 - val_loss: 0.4490 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "181/181 [==============================] - 55s 306ms/step - loss: 0.4976 - accuracy: 0.9669 - val_loss: 0.4484 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "181/181 [==============================] - 54s 296ms/step - loss: 0.4842 - accuracy: 0.9862 - val_loss: 0.4476 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model = image_classifier.ImageClassifier.create(\n",
        "    train_data = train_data,\n",
        "    validation_data = validation_data,\n",
        "    options=options,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Evaluation"
      ],
      "metadata": {
        "id": "-D9Jyp8mXDQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QmET7q-bdhca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340662df-dbae-437c-93e7-e02843636482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 14s 14s/step - loss: 0.4924 - accuracy: 1.0000\n",
            "Test loss:0.49236899614334106, Test accuracy:1.0\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(test_data)\n",
        "print(f'Test loss:{loss}, Test accuracy:{acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Conversion"
      ],
      "metadata": {
        "id": "4CDVD9QLXHQu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d8ceuBw5eVFQ"
      },
      "outputs": [],
      "source": [
        "model.export_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6_-0xgBteZSR",
        "outputId": "e73cef3e-054e-4bad-ee9d-2aa71a0283ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint  metadata.json  model.tflite  summaries\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2c57a9ce-f993-4aae-86ff-3bd5d9f78af7\", \"model.tflite\", 19201957)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!ls exported_model\n",
        "files.download('exported_model/model.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retraining parameters\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "You can further customize how the retraining process runs to adjust training time and potentially increase the retrained model's performance. *These parameters are optional*. Use the `ImageClassifierModelOptions` class and the `HParams` class to set these additional options.\n",
        "\n",
        "Use the `ImageClassifierModelOptions` class parameters to customize the existing model. It has the following customizable parameter that affects model accuracy:\n",
        "* `dropout_rate`: The fraction of the input units to drop. Used in dropout layer. Defaults to 0.05.\n",
        "\n",
        "Use the `HParams` class to customize other parameters related to training and saving the model:\n",
        "\n",
        "* `learning_rate`: The learning rate to use for gradient descent training. Defaults to 0.001.\n",
        "* `batch_size`: Batch size for training. Defaults to 2.\n",
        "* `epochs`: Number of training iterations over the dataset. Defaults to 10.\n",
        "* `steps_per_epoch`: An optional integer that indicates the number of training steps per epoch. If not set, the training pipeline calculates the default steps per epoch as the training dataset size divided by batch size.\n",
        "* `shuffle`: True if the dataset is shuffled before training. Defaults to False.\n",
        "* `do_fine_tuning`: If true, the base module is trained together with the classification layer on top. This defaults to False, which means only the classification layer is trained and pre-trained weights for the base module are frozen.\n",
        "* `l1_regularizer`: A regularizer that applies a L1 regularization penalty. Defaults to 0.0.\n",
        "* `l2_regularizer`: A regularizer that applies a L2 regularization penalty. Defaults to 0.0001.\n",
        "* `label_smoothing`: Amount of label smoothing to apply. See [`tf.keras.losses`](https://www.tensorflow.org/api_docs/python/tf/keras/losses) for more details. Defaults to 0.1.\n",
        "* `do_data_augmentation`: Whether or not the training dataset is augmented by applying random transformations such as cropping, flipping, etc. See [utils.image_preprocessing](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image) for details. Defaults to True.\n",
        "* `decay_samples`: Number of training samples used to calculate the decay steps and create the training optimizer. Defaults to 2,560,000.\n",
        "* `warmup_epochs`: Number of warmup steps for a linear increasing warmup schedule on the learning rate. Used to set up warmup schedule by `model_util.WarmUp`. Defaults to 2.\n",
        "\n"
      ],
      "metadata": {
        "id": "IppDtuvqrxvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hparams=image_classifier.HParams(epochs=15, export_dir=\"exported_model_2\")\n",
        "options = image_classifier.ImageClassifierOptions(supported_model=spec, hparams=hparams)\n",
        "model_2 = image_classifier.ImageClassifier.create(\n",
        "    train_data = train_data,\n",
        "    validation_data = validation_data,\n",
        "    options=options,\n",
        ")"
      ],
      "metadata": {
        "id": "W-OEEwV2r49P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323a9d7c-12f0-4205-ec9c-dc0d040c4ba3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_1 (KerasLayer)  (None, 1280)              4869168   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 6405      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4875573 (18.60 MB)\n",
            "Trainable params: 6405 (25.02 KB)\n",
            "Non-trainable params: 4869168 (18.57 MB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "181/181 [==============================] - 59s 298ms/step - loss: 1.7325 - accuracy: 0.2099 - val_loss: 1.5669 - val_accuracy: 0.3333\n",
            "Epoch 2/15\n",
            "181/181 [==============================] - 62s 342ms/step - loss: 1.5903 - accuracy: 0.3149 - val_loss: 1.4146 - val_accuracy: 0.5238\n",
            "Epoch 3/15\n",
            "181/181 [==============================] - 62s 343ms/step - loss: 1.3408 - accuracy: 0.5055 - val_loss: 1.2368 - val_accuracy: 0.6190\n",
            "Epoch 4/15\n",
            "181/181 [==============================] - 53s 294ms/step - loss: 1.1791 - accuracy: 0.6934 - val_loss: 1.0868 - val_accuracy: 0.8095\n",
            "Epoch 5/15\n",
            "181/181 [==============================] - 55s 306ms/step - loss: 1.0252 - accuracy: 0.7928 - val_loss: 0.9557 - val_accuracy: 0.9048\n",
            "Epoch 6/15\n",
            "181/181 [==============================] - 53s 295ms/step - loss: 0.9034 - accuracy: 0.8508 - val_loss: 0.8521 - val_accuracy: 0.9524\n",
            "Epoch 7/15\n",
            "181/181 [==============================] - 63s 351ms/step - loss: 0.8057 - accuracy: 0.8923 - val_loss: 0.7706 - val_accuracy: 0.9524\n",
            "Epoch 8/15\n",
            "181/181 [==============================] - 60s 333ms/step - loss: 0.7373 - accuracy: 0.9033 - val_loss: 0.7060 - val_accuracy: 0.9524\n",
            "Epoch 9/15\n",
            "181/181 [==============================] - 62s 344ms/step - loss: 0.6919 - accuracy: 0.9199 - val_loss: 0.6587 - val_accuracy: 0.9524\n",
            "Epoch 10/15\n",
            "181/181 [==============================] - 63s 347ms/step - loss: 0.6446 - accuracy: 0.9420 - val_loss: 0.6233 - val_accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "181/181 [==============================] - 60s 333ms/step - loss: 0.6223 - accuracy: 0.9448 - val_loss: 0.5925 - val_accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "181/181 [==============================] - 61s 336ms/step - loss: 0.5908 - accuracy: 0.9503 - val_loss: 0.5679 - val_accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "181/181 [==============================] - 55s 306ms/step - loss: 0.5540 - accuracy: 0.9641 - val_loss: 0.5500 - val_accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "181/181 [==============================] - 60s 333ms/step - loss: 0.5714 - accuracy: 0.9530 - val_loss: 0.5379 - val_accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "181/181 [==============================] - 63s 351ms/step - loss: 0.5509 - accuracy: 0.9613 - val_loss: 0.5259 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "QaPCKAHlsC1l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "0961b080-c033-4067-e5d6-1e20ced996d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b1e98e8aff74>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.export_model()"
      ],
      "metadata": {
        "id": "5z2m1G16sJr-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}